# -*- coding: utf-8 -*-
"""speech_to_text(ASR).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K24_6gM4peOZmApOf_KzYaWkyf7zwD7R

Loading the dataset
"""

!unzip /content/drive/MyDrive/dev-clean.zip -d /content/audio

path = '/content/audio'
print("/content/dev.zip", path)

import os

print("Files in dataset folder:")
print(os.listdir(path))

import os
import librosa

# Example audio file from the extracted dataset
audio_path = "/content/audio/dev-clean/6241/61946/6241_61946_000051_000001.wav"

# Load the audio
audio, sr = librosa.load(audio_path, sr=None)

print("Audio loaded successfully!")
print("Sample rate:", sr)
print("Duration (seconds):", librosa.get_duration(y=audio, sr=sr))

#To process all files
for root, dirs, files in os.walk(path):
    for file in files:
        if file.endswith(".wav"):
            full_path = os.path.join(root, file)
            print("Processing:", full_path)
            # load/process audio here

"""## Implement audio transcription for a provided audio file"""

!pip install -U openai-whisper

import glob

# Get all .wav files recursively in your dataset
audio_files = glob.glob("/content/audio/dev-clean/**/*.wav", recursive=True)

print(f"Found {len(audio_files)} audio files.")

from collections import Counter
import os
import glob

audio_files = glob.glob("/content/audio/dev-clean/**/*.wav", recursive=True)
folders = [os.path.basename(os.path.dirname(f)) for f in audio_files]
count = Counter(folders)

print(count)

import shutil
import os

folder_path = "/content/transcriptions_json"

# Check if folder exists
if os.path.exists(folder_path):
    shutil.rmtree(folder_path)  # Delete the entire folder and its contents
    print(f"‚úÖ Cleared: {folder_path}")
    os.makedirs(folder_path, exist_ok=True)  # Recreate empty folder
    print(f"üìÅ Recreated: {folder_path}")
else:
    print(f"‚ö†Ô∏è Folder not found: {folder_path}")

import random
from collections import defaultdict
import os
import glob
import json
import whisper

# Load Whisper model
model = whisper.load_model("small")

# Get all audio files
audio_files = glob.glob("/content/audio/dev-clean/**/*.wav", recursive=True)

# Group files by immediate parent folder
files_by_folder = defaultdict(list)
for f in audio_files:
    folder = os.path.basename(os.path.dirname(f))
    files_by_folder[folder].append(f)

# Select only 5 random folders
selected_folders = random.sample(list(files_by_folder.keys()), 5)

# Sample 2 files per selected folder
sample_files = []
files_per_folder = 2

for folder in selected_folders:
    files = files_by_folder[folder]
    if len(files) <= files_per_folder:
        sample_files.extend(files)  # take all if fewer
    else:
        sample_files.extend(random.sample(files, files_per_folder))

print(f"üìÇ Selected folders: {selected_folders}")
print(f"üéØ Total sampled files: {len(sample_files)}")

# Transcription + save to JSON
output_dir = "/content/transcriptions_json"
os.makedirs(output_dir, exist_ok=True)

for path in sample_files:
    print(f"üîä Transcribing: {path}")
    result = model.transcribe(path)

    # Create a dictionary for JSON output
    output_data = {
        "file_name": os.path.basename(path),
        "language": result["language"],
        "text": result["text"],
        "segments": [
            {
                "start": segment["start"],
                "end": segment["end"],
                "text": segment["text"]
            }
            for segment in result["segments"]
        ]
    }

    # Save to JSON
    json_name = os.path.basename(path).replace(".wav", ".json")
    with open(os.path.join(output_dir, json_name), 'w') as f:
        json.dump(output_data, f, indent=2)

    print(f"‚úÖ Saved to {json_name}")

!pip install jiwer

"""## Transcription + Speaker Diarization"""

!pip install git+https://github.com/pyannote/pyannote-audio

from huggingface_hub import login

login()  # will prompt for your Hugging Face token

# from huggingface_hub import whoami
# print(whoami())

from pyannote.audio import Pipeline

pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization", use_auth_token=True)

import shutil
import os

folder_path = "/content/diarized_outputs"

# Check if folder exists
if os.path.exists(folder_path):
    shutil.rmtree(folder_path)  # Delete the entire folder and its contents
    print(f"‚úÖ Cleared: {folder_path}")
    os.makedirs(folder_path, exist_ok=True)  # Recreate empty folder
    print(f"üìÅ Recreated: {folder_path}")
else:
    print(f"‚ö†Ô∏è Folder not found: {folder_path}")

import os
import json
from pyannote.audio import Pipeline

# Folder paths
transcription_folder = "/content/transcriptions_json"
audio_base_folder = "/content/audio/dev-clean"
output_folder = "/content/diarized_outputs"

os.makedirs(output_folder, exist_ok=True)

# Load diarization pipeline once (make sure your Hugging Face token is configured)
pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization", use_auth_token=True)

# Iterate over all transcription json files
for json_file in os.listdir(transcription_folder):
    if not json_file.endswith(".json"):
        continue

    json_path = os.path.join(transcription_folder, json_file)
    print(f"Processing {json_path} ...")

    # Load transcription result
    with open(json_path, "r") as f:
        result = json.load(f)

    # Derive audio file path from transcription filename
    # Assuming transcription filename: 1993_147965_000003_000003.json
    # and audio path: /content/audio/dev-clean/1993/147965/1993_147965_000003_000003.wav
    name_parts = json_file[:-5].split('_')
    if len(name_parts) < 2:
        print(f"Filename format unexpected: {json_file}")
        continue

    # Construct audio path dynamically from parts (adjust if your folder structure differs)
    year_folder = name_parts[0]
    id_folder = name_parts[1]
    audio_file_path = os.path.join(audio_base_folder, year_folder, id_folder, json_file[:-5] + ".wav")

    if not os.path.isfile(audio_file_path):
        print(f"Audio file not found: {audio_file_path}")
        continue

    # Run diarization
    diarization = pipeline(audio_file_path)

    segments = []
    for turn, _, speaker in diarization.itertracks(yield_label=True):
        segment_text = ""
        for s in result['segments']:
            if s['end'] > turn.start and s['start'] < turn.end:
                segment_text += s['text'] + " "
        segments.append({
            "start": round(turn.start, 2),
            "end": round(turn.end, 2),
            "speaker": speaker,
            "text": segment_text.strip()
        })

    output_data = {
        "file": result.get("file_name", os.path.basename(audio_file_path)),
        "language": result.get("language", "unknown"),
        "segments": segments
    }

    # Save diarized output JSON
    output_file = os.path.join(output_folder, json_file)
    with open(output_file, "w") as f:
        json.dump(output_data, f, indent=2)

    print(f"‚úÖ Saved diarized output: {output_file}")

print("‚úÖ All files processed.")

speakers = set()
for _, _, speaker in diarization.itertracks(yield_label=True):
    speakers.add(speaker)
print("Speakers detected:", speakers)